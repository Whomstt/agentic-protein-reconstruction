{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ce104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from transformers import BertForMaskedLM, BertTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bcaebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1edd5e5f38414e1c9f0d5797adef4553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tied weights mapping and config for this model specifies to tie bert.embeddings.word_embeddings.weight to cls.predictions.decoder.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "The tied weights mapping and config for this model specifies to tie cls.predictions.bias to cls.predictions.decoder.bias, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "\u001b[1mBertForMaskedLM LOAD REPORT\u001b[0m from: Rostlab/prot_bert\n",
      "Key                         | Status     |  | \n",
      "----------------------------+------------+--+-\n",
      "cls.seq_relationship.weight | UNEXPECTED |  | \n",
      "cls.seq_relationship.bias   | UNEXPECTED |  | \n",
      "bert.pooler.dense.weight    | UNEXPECTED |  | \n",
      "bert.pooler.dense.bias      | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.09893941879272461,\n",
       "  'token': 16,\n",
       "  'token_str': 'P',\n",
       "  'sequence': 'M A F S A E D V L K E Y D R R R R M E A L L L S L Y Y P N D R K L P D Y K E W S P P R V Q V E C P K A P V E W N N P P S'},\n",
       " {'score': 0.08192409574985504,\n",
       "  'token': 5,\n",
       "  'token_str': 'L',\n",
       "  'sequence': 'M A F S A E D V L K E Y D R R R R M E A L L L S L Y Y P N D R K L L D Y K E W S P P R V Q V E C P K A P V E W N N P P S'},\n",
       " {'score': 0.08001957833766937,\n",
       "  'token': 13,\n",
       "  'token_str': 'R',\n",
       "  'sequence': 'M A F S A E D V L K E Y D R R R R M E A L L L S L Y Y P N D R K L R D Y K E W S P P R V Q V E C P K A P V E W N N P P S'},\n",
       " {'score': 0.07410899549722672,\n",
       "  'token': 12,\n",
       "  'token_str': 'K',\n",
       "  'sequence': 'M A F S A E D V L K E Y D R R R R M E A L L L S L Y Y P N D R K L K D Y K E W S P P R V Q V E C P K A P V E W N N P P S'},\n",
       " {'score': 0.07231409847736359,\n",
       "  'token': 9,\n",
       "  'token_str': 'E',\n",
       "  'sequence': 'M A F S A E D V L K E Y D R R R R M E A L L L S L Y Y P N D R K L E D Y K E W S P P R V Q V E C P K A P V E W N N P P S'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained ProtBert model and tokeniser\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\n",
    "model = BertForMaskedLM.from_pretrained(\"Rostlab/prot_bert\")\n",
    "unmasker = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Test the model with one mask (expected output: L)\n",
    "unmasker(\"M A F S A E D V L K E Y D R R R R M E A L L L S L Y Y P N D R K L [MASK] D Y K E W S P P R V Q V E C P K A P V E W N N P P S\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
